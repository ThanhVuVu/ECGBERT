# ECGBERT Reproduction Project

This project implements ECGBERT, a BERT-based model for ECG signal analysis and classification. The project includes data preprocessing, pretraining, and fine-tuning pipelines for ECG signal processing.

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Project Structure](#project-structure)
- [Key Components](#key-components)
- [MIT-BIH Database Reader](#mit-bih-database-reader)
- [Installation](#installation)
- [Usage](#usage)
- [Data Format](#data-format)
- [File Descriptions](#file-descriptions)

## ğŸ¯ Overview

ECGBERT is a transformer-based model that learns representations from ECG signals through self-supervised pretraining. The project includes:

- **Data Preprocessing**: Noise removal, baseline wander correction, and signal cleaning
- **Pretraining**: Self-supervised learning on ECG signals using masked language modeling
- **Fine-tuning**: Task-specific fine-tuning for ECG classification tasks
- **Utilities**: Tools for reading and visualizing MIT-BIH database files

## ğŸ“ Project Structure

```
ECGBERT-reproduce-project-/
â”œâ”€â”€ mitdb/                          # MIT-BIH Arrhythmia Database files
â”‚   â”œâ”€â”€ 100.dat, 100.hea, 100.atr   # ECG record files
â”‚   â””â”€â”€ ...                         # Additional records
â”œâ”€â”€ pre_train/                      # Pretraining pipeline
â”‚   â”œâ”€â”€ ECGBERT_pretrain_main.py    # Main pretraining script
â”‚   â”œâ”€â”€ ECGBERT_pretrain_engine.py  # Training engine
â”‚   â”œâ”€â”€ ECGgetdata.py               # Data loading utilities
â”‚   â”œâ”€â”€ ECGpreprocessing.py         # Signal preprocessing
â”‚   â”œâ”€â”€ ECGsigpreprocessing.py      # Signal-level preprocessing
â”‚   â”œâ”€â”€ ECGsegmentation.py          # ECG wave segmentation
â”‚   â”œâ”€â”€ ECGClustering.py            # Waveform clustering
â”‚   â”œâ”€â”€ ECGSentenceGenerator.py     # Sentence generation for BERT
â”‚   â”œâ”€â”€ ECGDataset.py               # Dataset classes
â”‚   â”œâ”€â”€ pre_train.yaml              # Configuration file
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ misc.py                 # Utility functions
â”œâ”€â”€ fine_tune/                      # Fine-tuning pipeline
â”‚   â”œâ”€â”€ Fine_tune_main.py           # Main fine-tuning script
â”‚   â”œâ”€â”€ Fine_tune_engine.py         # Fine-tuning engine
â”‚   â”œâ”€â”€ ECG_Preprocessing.py        # Preprocessing for fine-tuning
â”‚   â”œâ”€â”€ ECG_Segmentation.py         # Segmentation
â”‚   â”œâ”€â”€ ECG_Beat_Sentence.py        # Beat-level sentence generation
â”‚   â””â”€â”€ models.py                   # Model definitions
â”œâ”€â”€ preprocessed/                   # Preprocessed data storage
â”‚   â”œâ”€â”€ ecg_raw_data.hdf5          # Raw ECG data
â”‚   â”œâ”€â”€ 0.2_ECGBERT_dataset.hdf5    # Processed dataset
â”‚   â””â”€â”€ clustering_models/         # Clustering models
â”œâ”€â”€ read_mitdb_files.py            # MIT-BIH file reader utility
â”œâ”€â”€ custom_vocab.txt               # Custom vocabulary
â””â”€â”€ sf1.0_bs32_lr0.0005_ep500_ecgbert_model.pth  # Pretrained model
```

## ğŸ”§ Key Components

### 1. Preprocessing Pipeline (`pre_train/ECGpreprocessing.py`)

The preprocessing pipeline cleans and filters ECG signals:

- **Missing Value Handler**: Interpolates missing/NaN values using linear interpolation
- **Bandstop Filter**: Removes 50-60 Hz power line interference using Butterworth filter
- **Baseline Wander Removal**: Removes low-frequency drift using wavelet decomposition (Daubechies db4)
- **Signal Processor**: Orchestrates the entire preprocessing pipeline

**Processing Flow:**
```
Raw ECG Signal â†’ Missing Value Handling â†’ Bandstop Filtering â†’ Baseline Removal â†’ Clean Signal
```

### 2. Pretraining Pipeline

The pretraining pipeline includes:

- **Data Loading**: Reads ECG data from HDF5 files
- **Segmentation**: Identifies P, QRS, and T waves in ECG signals
- **Clustering**: Groups similar waveforms using K-means clustering
- **Sentence Generation**: Creates tokenized sentences for BERT training
- **Masked Language Modeling**: Self-supervised pretraining on ECG signals

### 3. Fine-tuning Pipeline

Task-specific fine-tuning for downstream ECG classification tasks, including:
- **Heartbeat Classification**: Binary (Normal/Abnormal) or multi-class beat classification
- **AFIB Detection**: Atrial fibrillation detection
- Custom downstream tasks can be added by implementing the preprocessing pipeline

See `fine_tune/FINETUNING_GUIDE.md` for detailed instructions.

## ğŸ“Š MIT-BIH Database Reader

The `read_mitdb_files.py` script provides a utility to read and display MIT-BIH Arrhythmia Database files in a human-readable format.

### Features

- **Header Information**: Displays record metadata, signal details, and patient information
- **Signal Data**: Shows sample ECG values and statistics
- **Annotations**: Displays beat annotations with types and timestamps

### Usage

```bash
python read_mitdb_files.py
```

The script reads record `100` from the `mitdb/` directory by default. To read a different record, modify the `record_name` variable in the `main()` function.

### Output

The script displays:
- **Header Information**: Record name, sampling frequency, signal channels, patient info
- **Signal Samples**: First N samples from each channel with values in mV
- **Signal Statistics**: Min, max, mean, and standard deviation for each channel
- **Annotations**: Beat type distribution and detailed annotation list with timestamps

### Example Output

```
================================================================================
HEADER INFORMATION for record: 100
================================================================================

Record Name: 100
Number of Signals: 2
Sampling Frequency: 360 Hz
Number of Samples: 650000
Duration: 1805.56 seconds (30.09 minutes)

Signal 1: MLII
  Format: 212
  Gain: 200.0
  Units: mV
  ...

Annotation Symbols Distribution:
  'N': 2239 occurrences - Normal beat
  'A':   33 occurrences - Atrial premature beat
  'V':    1 occurrences - Premature ventricular contraction
  '+':    1 occurrences - Rhythm change
```

## ğŸ’» Installation

### Dependencies

The project requires the following Python packages:

```bash
pip install torch torchvision
pip install numpy scipy
pip install h5py
pip install pywavelets
pip install wfdb
pip install pyyaml
```

### Required Libraries

- **PyTorch**: Deep learning framework
- **NumPy/SciPy**: Numerical computing and signal processing
- **h5py**: HDF5 file handling
- **PyWavelets**: Wavelet transforms for baseline removal
- **wfdb**: MIT-BIH database file reading
- **PyYAML**: Configuration file parsing

## ğŸš€ Usage

### 1. Reading MIT-BIH Files

```bash
python read_mitdb_files.py
```

### 2. Pretraining

```bash
cd pre_train
python ECGBERT_pretrain_main.py --config pre_train.yaml
```

### 3. Fine-tuning

```bash
cd fine_tune
python Fine_tune_main.py [arguments]
```

## ğŸ“ Data Format

### Input Format

- **MIT-BIH Database**: Standard `.dat`, `.hea`, and `.atr` files
- **HDF5 Files**: Processed ECG data stored in HDF5 format with groups for each record

### HDF5 Structure

```
ecg_data.hdf5
â”œâ”€â”€ record_100/
â”‚   â”œâ”€â”€ signal: (channels, samples) array
â”‚   â”œâ”€â”€ fs: sampling frequency (attribute)
â”‚   â”œâ”€â”€ seq_len: sequence length (attribute)
â”‚   â””â”€â”€ Source: source file name (attribute)
â””â”€â”€ record_101/
    â””â”€â”€ ...
```

## ğŸ“„ File Descriptions

### Pretraining Files

- **`ECGBERT_pretrain_main.py`**: Main entry point for pretraining
- **`ECGBERT_pretrain_engine.py`**: Training loop and optimization
- **`ECGgetdata.py`**: Loads ECG data from files into HDF5 format
- **`ECGpreprocessing.py`**: Main preprocessing pipeline (noise removal, baseline correction)
- **`ECGsigpreprocessing.py`**: Signal-level preprocessing utilities
- **`ECGsegmentation.py`**: Identifies P, QRS, T waves in ECG signals
- **`ECGClustering.py`**: Clusters similar ECG waveforms
- **`ECGSentenceGenerator.py`**: Generates tokenized sentences for BERT
- **`ECGDataset.py`**: PyTorch dataset classes for ECG data

### Fine-tuning Files

- **`Fine_tune_main.py`**: Main entry point for fine-tuning
- **`Fine_tune_engine.py`**: Fine-tuning training loop
- **`ECG_Preprocessing.py`**: Preprocessing for fine-tuning tasks
- **`ECG_Segmentation.py`**: Beat-level segmentation
- **`ECG_Beat_Sentence.py`**: Beat-level sentence generation
- **`models.py`**: Model architecture definitions

### Utility Files

- **`read_mitdb_files.py`**: MIT-BIH database file reader and visualizer
- **`custom_vocab.txt`**: Custom vocabulary for tokenization

## ğŸ” Beat Type Annotations

The MIT-BIH database uses the following beat type annotations:

- **N**: Normal beat
- **L**: Left bundle branch block beat
- **R**: Right bundle branch block beat
- **A**: Atrial premature beat
- **a**: Aberrated atrial premature beat
- **J**: Nodal (junctional) premature beat
- **S**: Supraventricular premature beat
- **V**: Premature ventricular contraction
- **E**: Ventricular escape beat
- **F**: Fusion of ventricular and normal beat
- **Q**: Unclassifiable beat
- **/**: Paced beat
- **f**: Fusion of paced and normal beat
- **+**: Rhythm change
- **~**: Signal quality change

## ğŸš€ Running on Kaggle

This project is optimized for running on Kaggle with GPU support. See `KAGGLE_SETUP.md` for detailed instructions.

**Quick Start on Kaggle:**
1. Upload your data (MIT-BIH database, pretrained model, clustering models) as Kaggle datasets
2. Create a new GPU-enabled notebook
3. Clone this repository or upload as dataset
4. Install dependencies: `!pip install -q wfdb neurokit2 pywavelets`
5. Run: `python fine_tune/Fine_tune_heartbeat_main_kaggle.py`

See `KAGGLE_NOTEBOOK_TEMPLATE.ipynb` for a ready-to-use notebook template.

## ğŸ“š References

- MIT-BIH Arrhythmia Database: https://physionet.org/content/mitdb/1.0.0/
- WFDB Python Package: https://github.com/MIT-LCP/wfdb-python

## ğŸ“ Notes

- The preprocessing pipeline is designed to handle various ECG signal qualities and artifacts
- All preprocessing steps include error handling to prevent data corruption
- The project uses HDF5 format for efficient storage and loading of large ECG datasets
- Configuration files (YAML) allow easy parameter tuning without code changes

## ğŸ¤ Contributing

This is a reproduction project for research purposes. For issues or improvements, please refer to the original ECGBERT paper and implementation.

---

**Last Updated**: 2024

